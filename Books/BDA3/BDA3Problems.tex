\font\big=cmbx10 scaled\magstep1
\font\bigger=cmbx10 scaled\magstep3

\topglue 0.5in
\centerline{\bigger Problems from BDA 3}
\vskip 0.5in

\noindent
{\bigger Chapter 1}
\vskip 0.2in

\noindent {\big Problem 1} \hfil \break
\noindent a) $P\left(y\right) \sim 1/2 \left(N\left(\mu_1, \sigma^2\right) + 
N \left(\mu_2, \sigma^2\right)\right)$ \hfil \break
\noindent b) 
$$
\eqalign{
 P \left( \theta = 1 | y \right) &= {P\left(y | \theta = 1\right) P\left(\theta = 1\right)
  \over P\left(y | \theta = 1\right) P\left(\theta = 1\right) +
  P\left(y | \theta = 2\right) P\left(\theta = 2\right)} \cr &=
  \left(1 + \exp \left[ \left( 2 y \left(\mu_2 - \mu_1\right) + 
   \mu_2^2 - \mu_1^2\right) / 2 \sigma^2 \right] \right)^{-1} }.
$$

\noindent {\big Problem 3}\hfil \break
\noindent We have $P\left(xx\right) = p^2$, $P\left(xX\right) = 2 p \left(1-p\right)$
(where we ignore ordering, so that Xx is counted as the same as xX),
and so $P\left(XX\right) = 1 - p^2 - 2 p \left(1-p\right) = \left(1 - p\right)^2$.
Now 
$$
P\left(xX | \rm{brown}\right) =  {1 \cdot P\left(xX\right) \over
1 \cdot P\left(xX\right) + 1 \cdot P\left(XX\right) + 0 \cdot P\left(xx\right)} = 
 {2 p \over 1 + p},
$$
and therefore $P\left(XX | \rm{brown}\right) = \left(1-p\right)/\left(1 + p\right)$.

The complication here is normalization.  So what we want to compute is
$$P\left(xX | p_1=\rm{brown}, p_2 = \rm{brown}\right) \over
P\left(xX | p_1=\rm{brown}, p_2 = \rm{brown}\right) +
P\left(XX | p_1=\rm{brown}, p_2 = \rm{brown}\right).$$
Starting with the first term
$$
\eqalign{
P\left(xX | p_1=\rm{brown}, p_2 = \rm{brown}\right)  &= P\left(xX | p_1=xX, p_2=xX\right)
 P\left(xX\right)^2 \cr &+ 2 P\left(xX | p_1=xX, p_2=XX\right) P\left(xX\right) P\left(XX\right)
 \cr &+ P\left(xX | p_1=xx, p_2=xx\right) P\left(xx\right)^2 \cr 
  &= {1 \over 2} \left({2 p \over 1+p}\right)^2 + 2 {1 \over 2} {2 p \over 1 + p} {1 - p \over 1 + p} + 0
  \left({1 - p \over 1 + p}\right)^2 \cr &= {2 p \over \left(1 + p\right)^2},
}
$$
where things like $P\left(xX | p_1=xX, p_2 = XX\right) = 1/2$ come from inheritance
squares.

Similarly
$$
\eqalign{
P\left(XX | p_1=\rm{brown}, p_2 = \rm{brown}\right)  &= P\left(XX | p_1=xX, p_2=xX\right)
 P\left(xX\right)^2 \cr &+ 2 P\left(XX | p_1=xX, p_2=XX\right) P\left(xX\right) P\left(XX\right)
 \cr &+ P\left(XX | p_1=xx, p_2=xx\right) P\left(xx\right)^2 \cr 
  &= {1 \over 4} \left({2 p \over 1+p}\right)^2 + 2 {1 \over 2} {2 p \over 1 + p} {1 - p \over 1 + p} + 
  1 \cdot \left({1 - p \over 1 + p}\right)^2 \cr &= {1 \over \left(1 + p\right)^2}.
}
$$
Therefore, the steady state fraction is
$${P\left(xX | p_1=\rm{brown}, p_2 = \rm{brown}\right) \over
P\left(xX | p_1=\rm{brown}, p_2 = \rm{brown}\right) +
P\left(XX | p_1=\rm{brown}, p_2 = \rm{brown}\right)} = {2 p \over 1 + 2 p}
$$
as claimed.

If Judy has brown eyed kids with a xX, the outcome depends on Judy's genome:
$$
\eqalign{
 P\left(\rm{child} = \rm{brown} | \rm{Judy}=xX\right) &= P\left(xX | J=xX\right)
 + P\left(XX | J=xX\right) = 1/2 + 1/4 = 3/4 \cr
 P\left(\rm{child} = \rm{brown} | \rm{Judy} = XX\right) &= 1}.
 $$
So, if Judy has $n$ brown eyed children, we have
$$
 P\left(J=xX | n\right) = {P\left(n | xX\right) P\left(xX\right) \over
  P\left(n | xX\right) P\left(xX\right) + P\left(n | XX\right) P\left(XX\right)} =
  {\left(3 \over 4\right)^n 2 p \over \left(3 / 4\right)^n 2 p + 1}
$$

\noindent {\big Problem 6}\hfil \break
\noindent 
The proportion of births that are fraternal twins is 1/125, and 1/4 of those are
both males.  The proportion of identical twins is 1/300, and 1/2 of those are both
males.  Thus
$$
  P\left(i | \rm{both\,male}\right) = 
  {P\left( \rm{both\,male} | i\right) P\left(i\right) \over
   P\left( \rm{both\,male} | i\right) P\left(i\right) +
   P\left( \rm{both\,male} | f\right) P\left(f\right)} = 
    {1/2 \cdot 1/300 \over 1/2 \cdot 1/300 + 1 / 4 \cdot 1 / 125} = {5 \over 11}.
$$

\vskip 0.5in
\noindent
{\bf \bigger Chapter 2}
\vskip 0.2in

\noindent {\big Problem 1} \hfil \break
The prior distribution is $\rm{Beta}\left(4 ,4\right) \propto \theta^3 \left(1 - \theta\right)^3$,
while the probability of fewer than 3 heads conditional on $\theta$ is 
$P\left(n < 3 | \theta\right) = P\left(0 | \theta\right) + P\left(1 | \theta\right) +
P\left(2 | \theta\right) = {10 \choose 0} \left(1 - \theta\right)^{10} +
{10 \choose 1} \theta \left(1 - \theta\right)^9 + {10 \choose 2} \theta^2 \left(1 - \theta\right)^8$.
We therefore have $P\left(\theta | n < 3\right) \propto
{10 \choose 0} \theta^3 \left(1 - \theta\right)^{13} +
{10 \choose 1} \theta^4 \left(1 - \theta\right)^{12} + {10 \choose 2} \theta^5 \left(1 - \theta\right)^{11}$.
Normalizing by requiring $\int_0^1\,d\theta P\left(\theta | n < 3\right) = 1$ gives
$$
 P\left(\theta | n < 3 \right) = {7735 \over 8} \theta^3 \left(1 - \theta\right)^11
  \left(1 + 8 \theta + 36 \theta^2\right).
$$
The mode is 0.2812, the mean $39/128$, and the variance 0.0139.  The 95\% limits
are 0.109 to 0.540.

\vskip 0.2in
\noindent {\big Problem 2} \hfil \break
We have $P\left(H | C_1\right) = 0.6$ and $P\left(H | C_2\right) = 0.4$, so
$$
 P\left(C_1 | T, T\right) = {P\left(T, T | C_1\right) P\left(C_1\right) \over 
  P\left(T, T | C_1\right) P\left(C_1\right) + P\left(T, T | C_2\right) P\left(C_2\right)}.
$$
Now $P\left(T,T | C_1\right) = 0.4^2$ and $P\left(T, T | C_2\right) = 0.6^2$,
so assuming priors $P\left(C_1\right) = P\left(C_2\right) = 1/2$, we have
$P\left(C_1 | T, T\right) = 0.3077$.

The probability of making N spins until a head comes up is the probability of
getting N-1 consecutive tails followed by one head, or $\theta \left(1 - \theta\right)^{N-1}$.
Thus the expected number is therefore (with the aid of Mathematica)
$$
 E\left(N | \theta\right) = {\sum_{N=1}^\infty N \theta \left(1-\theta\right)^{N-1} \over
  \sum_{N=1}^\infty \theta \left(1 - \theta\right)^{N-1}} = {1 \over \theta}.
$$
Therefore, the expectation is $0.3077 / 0.6 + \left(1-0.3077\right) / 0.4 = 2.2436$

Alternatively, we could compute the probability distribution directly and do the sums on
that using
$$
 P\left( \left(N-1\right) T, H | T, T \right) = 0.6 \left(1-0.6\right)^{N-1} \cdot 0.3077
  0.4 \left(1 - 0.4\right)^{N-1} \cdot \left(1 - 0.3077\right),
$$
which gives the same answer.

\vskip 0.2in
\noindent {\big Problem 14} \hfil \break
a) It suffices to consider $\left(y - \theta\right)^2/\sigma^2 + \left(\theta - \mu_0\right)^2/\tau_0^2$.
Expanding this, and discarding any terms that do not contain $\theta$, since they can be
absorbed into the proportioinality, gives $\theta^2 \left(1/\sigma^2 + 1/\tau_0^2\right) -
2 \theta \left(y / \sigma^2 + \mu_0 / \tau_0^2\right)$.  Now, complete the square
using the standard $a x^2 + b x = a\left(x + d\right)^2 + e$ where $d = b/2a$ and
$e = -b^2 / 4a$ with $a = \left(1 / \sigma^2 + 1 / \tau_0^2\right)$ and 
$b = -2 \left(y / \sigma^2 + \mu_0 / \tau_0^2\right)$.  This $e$ doesn't depend on $\theta$,
and can be discarded, leaving
$$
 p\left(\theta | y\right) \propto \exp \left(-{1 \over 2} \left({1 \over \sigma^2} + {1 \over \tau_0^2}
 \right) \left(\theta - {y / \sigma^2 + \mu_0 / \tau_0^2 \over 1 / \sigma^2 + 1 / \tau_0^2}
 \right)^2\right),
$$
which is formulae 2.9 and 2.10.
\end